{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's learning of refactored model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to define weaknesses of the approach from the article:\n",
    "1. Using of ResNet50 as backbone (Some more powerfull models can be used)\n",
    "2. Assumption about uniform distribution of data(num of lesions)\n",
    "3. Loss function and lambda parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can be done with first weakness. We can change it with more strong model like SWIN Transformer (tiny) from Microsoft. That model performed better in this task compared to ResNet50. Now, transformers are performing well not only in NLP tasks, but also in CV. However, that model provide new approach(patching). Also, we can add some self-attention layers.\n",
    "\n",
    "Second, some new approach to multi-task learning can be applied. In article they use standard hard parametr sharing, but also soft parametr sharing can be used. \n",
    "\n",
    "Also, X. Sun et al. proposed, <a href=\"https://arxiv.org/abs/1911.12423\">“AdaShare: Learning What to Share for Efficient Deep Multi-Task Learning”</a> (2020). The primary goal of the researchers was to specify a single multi-layer architecture for MTL and train a policy that determines which layers to share by multiple tasks, which layers to use for specific tasks and which layers to skip for all tasks while ensuring the model provides highest performance at its most compact form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second weakness is not too obvious. First, we can, that distribtion of data(from EDA) is not uniform (it's assumption, but the likehood of the value being below average is higher than the likelihood of being higher). Some other distributions can be tried (Student's t-distribution, Exponential and etc), but also we can try find by use of EM algorithm (data distribution can be mixture of gaussian)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last question is about parametr lambda in loss function. We can try to learn that parametrs. I tried one approach from <a href=\"https://towardsdatascience.com/multi-task-learning-with-pytorch-and-fastai-6d10dc7ce855\"> here </a> and it didn't worked well. The problem is that model starts to optimize one loss and give small weights to others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we cat try to expand dataset by some simple transformations (for example by albumination). From data we know, that majority of data have low bliriness(contrast). We can change it and add new images to dataset. So, it will help us to improve stability of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import to_absolute_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GlobalHydra.instance().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize(config_path=\"./conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = compose(config_name=\"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LDL import factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cfg):\n",
    "\n",
    "    cfg['dataset_local_train']['data_path'] = to_absolute_path(cfg['dataset_local_train']['data_path'])\n",
    "    cfg['dataset_local_train']['data_file'] = to_absolute_path(cfg['dataset_local_train']['data_file'])\n",
    "\n",
    "    cfg['dataset_local_test']['data_path'] = to_absolute_path(cfg['dataset_local_test']['data_path'])\n",
    "    cfg['dataset_local_test']['data_file'] = to_absolute_path(cfg['dataset_local_test']['data_file'])\n",
    "\n",
    "    trainer, model, train_loader, test_loader = factory.get_trainer(\n",
    "        cfg['backbone']['name'],\n",
    "        cfg['dataset_local_train'],\n",
    "        cfg['dataset_local_test'],\n",
    "        cfg['logger'],\n",
    "        cfg['trainer']\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, test_loader)\n",
    "\n",
    "    return trainer, model, train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watch process of learning here https://wandb.ai/solidcake98/ImageAcneAnalysis/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I provide the picture of working of web app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./jupyter_img/TestService.png\" width=1200 height=800/>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a105a4da89a176d1f07730376f264f731648881d1aace75cc56f6745fe1f2e7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
